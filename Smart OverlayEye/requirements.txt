# Smart OverlayEye â€” app and vision LLM server
# Install: pip install -r requirements.txt
# System: Homebrew tesseract, (optional) portaudio for pyaudio

PySide6>=6.6,<6.11
mss>=9.0
Pillow>=10.0
pytesseract>=0.3.10
requests>=2.28
pynput>=1.7
numpy>=1.24

# Vision LLM server (run separately: python -m llama_cpp.server ...)
llama-cpp-python>=0.2.0

# OWL-ViT + ONNX (optimum pins transformers)
transformers>=4.26,<4.40
torch>=2.0
onnxruntime>=1.15
optimum>=1.18,<2

# Optional: if you run an API layer
uvicorn>=0.22
fastapi>=0.100
anyio>=3.7
